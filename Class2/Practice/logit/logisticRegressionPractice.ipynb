{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the practice for logistic regression\n",
    "# Goals:\n",
    "## 1 - Fit logistic model (Sklearn and GLM- statsmodel)\n",
    "## 2 - KPIs to evaluate binary classification model(logistic model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression #, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_curve, accuracy_score, roc_auc_score\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "from dmba import classificationSummary\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths to data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path('.').resolve().parents[1] / 'IntermediateLevel/DataScienceProgram/Class2/Practice/logit'\n",
    "LOAN3000_CSV = DATA / 'loan3000.csv'\n",
    "# LOAN_DATA_CSV = DATA / 'loan_data.csv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = pd.read_csv(LOAN3000_CSV)\n",
    "print(loan_data.shape)\n",
    "print(loan_data.columns)\n",
    "print(loan_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = loan_data.drop(['Unnamed: 0'], axis=1).copy()\n",
    "loan_data.columns=['outcome', 'purpose', 'dti', 'borrower_score', 'payment_inc_ratio']\n",
    "loan_data['dv'] = [1 if out==\"default\" else 0 for out in loan_data['outcome']]\n",
    "\n",
    "print(loan_data.shape)\n",
    "print(loan_data.columns)\n",
    "print(loan_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nm in loan_data.columns:\n",
    "    print(\"\\n{}\".format(nm))\n",
    "    print(loan_data[nm].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"event rate is: {}\".format(sum(loan_data['dv'])*100/len(loan_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numcols=list(loan_data.describe().columns)\n",
    "num_stats = loan_data.describe().transpose() \n",
    "num_stats[\"nuniqueWna\"]= loan_data[numcols].nunique(dropna=False) \n",
    "num_stats[\"nunique\"]= loan_data[numcols].nunique()\n",
    "num_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.groupby([\"purpose\", 'dv']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose_risk = pd.concat([loan_data.groupby([\"purpose\"]).size(), loan_data.groupby([\"purpose\"]).sum()['dv']], axis=1)\n",
    "purpose_risk.columns = ['count','default']\n",
    "purpose_risk['default_rate']=purpose_risk['default']/purpose_risk['count']\n",
    "print(purpose_risk.sort_values(['default_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = loan_data[numcols].corr()\n",
    "print(\"Correlation Matrix \\n {}\".format(corr))\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True)\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This dataset do not have too much variables, therefore just did a light EDA. You can plot bar, histogram and bar/target, hist/targert. For this data just need to convert nominal to numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression and the GLM\n",
    "The package _scikit-learn_ has a specialised class for `LogisticRegression`. _Statsmodels_ has a more general method based on generalized linear model (GLM).\n",
    "\n",
    "In scikit-learn, your target variable could be numerical or categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['purpose', 'dti', 'borrower_score', 'payment_inc_ratio']\n",
    "outcome = 'outcome'\n",
    "\n",
    "loan, loan_test = train_test_split(loan_data, test_size=0.2)\n",
    "\n",
    "X_train = pd.get_dummies(loan[predictors], prefix='', prefix_sep='', drop_first=True)\n",
    "y_train = loan[outcome] \n",
    "\n",
    "X_test = pd.get_dummies(loan_test[predictors], prefix='', prefix_sep='', drop_first=True)\n",
    "y_test = loan_test[outcome] \n",
    "\n",
    "#C=1e42,\n",
    "logit_reg = LogisticRegression(penalty='l2', C=1e42, solver='liblinear')\n",
    "logit_reg.fit(X_train, y_train)\n",
    "\n",
    "print('intercept ', logit_reg.intercept_[0])\n",
    "print('classes', logit_reg.classes_)\n",
    "pd.DataFrame({'coeff': logit_reg.coef_[0]}, \n",
    "             index=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['purpose', 'dti', 'borrower_score', 'payment_inc_ratio']\n",
    "outcome = 'dv'\n",
    "\n",
    "loan, loan_test = train_test_split(loan_data, test_size=0.2)\n",
    "\n",
    "X_train = pd.get_dummies(loan[predictors], prefix='', prefix_sep='', drop_first=True)\n",
    "y_train = loan[outcome] \n",
    "\n",
    "X_test = pd.get_dummies(loan_test[predictors], prefix='', prefix_sep='', drop_first=True)\n",
    "y_test = loan_test[outcome] \n",
    "\n",
    "#C=1e42,\n",
    "logit_reg2 = LogisticRegression(penalty='l2', C=1e42, solver='liblinear')\n",
    "logit_reg2.fit(X_train, y_train)\n",
    "\n",
    "print('intercept ', logit_reg2.intercept_[0])\n",
    "print('classes', logit_reg2.classes_)\n",
    "pd.DataFrame({'coeff': logit_reg2.coef_[0]}, \n",
    "             index=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted Values from Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = pd.DataFrame(logit_reg.predict_proba(X_train),\n",
    "                    columns=logit_reg.classes_)\n",
    "pred_test = pd.DataFrame(logit_reg.predict_proba(X_test),\n",
    "                    columns=logit_reg.classes_)\n",
    "print(pred_train.describe())\n",
    "\n",
    "print(pred_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = pd.DataFrame(logit_reg2.predict_proba(X_train),\n",
    "                    columns=logit_reg2.classes_)\n",
    "pred_test = pd.DataFrame(logit_reg2.predict_proba(X_test),\n",
    "                    columns=logit_reg2.classes_)\n",
    "print(pred_train.describe())\n",
    "\n",
    "print(pred_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM Model - logistic regression\n",
    "For comparison, here the GLM model using _statsmodels_. This method requires that the outcome is mapped to numbers. \n",
    "##### use GLM (general linear model) with the binomial family to fit a logistic regression\n",
    "##### Notice: use this GLM module you can fit a series of model by changing the link function which specified in the family option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_reg_sm = sm.GLM(y_train, sm.add_constant(X_train), \n",
    "                      family=sm.families.Binomial())\n",
    "logit_result = logit_reg_sm.fit()\n",
    "print(logit_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Classification Models\n",
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_reg2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_reg2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "pred_y = logit_reg2.predict(X_test)\n",
    "true_y = y_test \n",
    "true_pred = pd.DataFrame({'True': true_y, 'Pred': pred_y})\n",
    "true_pred['Cnt'] = [1] *len(true_y)\n",
    "confM=true_pred.groupby(['True', 'Pred']).size()\n",
    "\n",
    "print(\"\\nConfusion Matrix in 1D array\\n {}\".format(confM))\n",
    "\n",
    "print(\"\\nConfusion Matrix in 2 by 2 Table Format\\n {}\".format(pd.pivot_table(true_pred, values='Cnt', index=['True'],\n",
    "                    columns=['Pred'], aggfunc=np.sum)))\n",
    "\n",
    "\n",
    "\n",
    "conf_matorg = pd.DataFrame([[confM[1,1], confM[1,0]], [confM[0,1], confM[0,0]]],\n",
    "                       index=['Y = default', 'Y = paid off'],\n",
    "                       columns=['Yhat = default', 'Yhat = paid off'])\n",
    "print(\"\\nConfusion Matrix in 2 by 2 Re-orgnized Table Format\\n {}\".format(conf_matorg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, logit_reg2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package _dmba_ contains the function `classificationSummary` that prints confusion matrix and accuracy for a classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificationSummary(y_test, logit_reg2.predict(X_test), \n",
    "                      class_names=logit_reg2.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision, Recall, and Specificity\n",
    "#### Precision = tp/(tp+fp)\n",
    "#### Recall (Sensitivity) = tp/(tp+fn)\n",
    "#### Specificity = tn/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, logit_reg2.predict(X_test)).ravel()\n",
    "print('Precision:   {}'.format(tp/(tp+fp))) \n",
    "print('Recball:     {}'.format(tp/(tp+fn)))\n",
    "print('Specificity: {}'.format(tn/(tn+fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_test, logit_reg2.predict(X_test))\n",
    "print('Precision', conf_mat[1, 1] / sum(conf_mat[:, 1]))\n",
    "print('Recball', conf_mat[1, 1] / sum(conf_mat[1, :]))\n",
    "print('Specificity', conf_mat[0, 0] / sum(conf_mat[0, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _scikit-learn_ function `precision_recall_fscore_support` returns\n",
    "precision, recall, fbeta_score and support. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(y_test, logit_reg2.predict(X_test), \n",
    "                                labels=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['paid off', 'default']\n",
    "print(classification_report(true_y, pred_y, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve\n",
    "The function `roc_curve` in _Scikit-learn_ calculates all the information that is required for plotting a ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, (logit_reg2.predict_proba(X_test)[:, 1]), \n",
    "                                 pos_label=1)\n",
    "roc_df = pd.DataFrame({'recall': tpr, 'specificity': 1 - fpr})\n",
    "\n",
    "ax = roc_df.plot(x='specificity', y='recall', figsize=(4, 4), legend=False)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(1, 0)\n",
    "ax.plot((1, 0), (0, 1))\n",
    "ax.set_xlabel('specificity')\n",
    "ax.set_ylabel('recall')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC\n",
    "Accuracy can easily be calculated using the _scikit-learn_ function `accuracy_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(roc_df.recall[:-1] * np.diff(1 - roc_df.specificity)))\n",
    "print(roc_auc_score(y_test, (logit_reg2.predict_proba(X_test)[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, (logit_reg.predict_proba(X_test)[:,0]), \n",
    "                                 pos_label=1)\n",
    "roc_df = pd.DataFrame({'recall': tpr, 'specificity': 1 - fpr})\n",
    "\n",
    "ax = roc_df.plot(x='specificity', y='recall', figsize=(4, 4), legend=False)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(1, 0)\n",
    "# ax.plot((1, 0), (0, 1))\n",
    "ax.set_xlabel('specificity')\n",
    "ax.set_ylabel('recall')\n",
    "ax.fill_between(roc_df.specificity, 0, roc_df.recall, alpha=0.3)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score \n",
    "### F1 = 2 * Precision* Recall/(Precision + Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 SCORE for Default:  {}'.format(2*(tp/(tp+fp))*(tp/(tp+fn))/((tp/(tp+fp))+(tp/(tp+fn)))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
